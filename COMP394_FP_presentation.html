<!DOCTYPE html>
<html lang="en"><head>
<script src="COMP394_FP_presentation_files/libs/clipboard/clipboard.min.js"></script>
<script src="COMP394_FP_presentation_files/libs/quarto-html/tabby.min.js"></script>
<script src="COMP394_FP_presentation_files/libs/quarto-html/popper.min.js"></script>
<script src="COMP394_FP_presentation_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="COMP394_FP_presentation_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="COMP394_FP_presentation_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="COMP394_FP_presentation_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="COMP394_FP_presentation_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.555">

  <meta name="author" content="Charles Batsaikhan, William Acosta Lora, Daisy Chan">
  <title>COMP394 Project Presentation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="COMP394_FP_presentation_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="COMP394_FP_presentation_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="COMP394_FP_presentation_files/libs/revealjs/dist/theme/quarto.css">
  <link href="COMP394_FP_presentation_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="COMP394_FP_presentation_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">COMP394 Project Presentation</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Charles Batsaikhan, William Acosta Lora, Daisy Chan 
</div>
</div>
</div>

</section>
<section id="introduction-and-research-question" class="slide level2 scrollable smaller">
<h2>Introduction and Research Question</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Introduction</a></li><li><a href="#tabset-1-2">Research Question</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<ul>
<li>What we’re studying:
<ul>
<li>Reddit’s r/AmITheAsshole (AITA) forum, where users vote YTA (you’re the asshole), NTA (not the asshole), ESH (everyone sucks here), or NAH (no assholes here).</li>
</ul></li>
<li>Why it matters
<ul>
<li>These public “verdicts” shape reputations online and fuel cancel‑culture talk.</li>
</ul></li>
<li>Our data
<ul>
<li>Hugging Face dataset by Oguzz07</li>
<li>Posts 900 comments, verdict labels kept, usernames removed for privacy.</li>
</ul></li>
</ul>
</div>
<div id="tabset-1-2">
<ul>
<li>Research Question:
<ul>
<li>Testing whether our sentiment is directed towards our original poster (OP) or other parties?</li>
</ul></li>
<li>How we’ll test it:
<ul>
<li>BERT Model</li>
<li>Gemini</li>
</ul></li>
</ul>
</div>
</div>
</div>
<aside class="notes">
<p>We’re diving into r/AmITheAsshole, a subreddit where people post real‑life dilemmas and get judged by strangers. Each comment carries a clear verdict—you’re the jerk (YTA), you’re not (NTA), or one of two middle‑ground options. That makes AITA a gold‑mine for studying moral judgment online.</p>
<p>Why should we care? Because these verdicts don’t stay on Reddit. They end up in news stories, TikToks, and sometimes real‑world backlash—so understanding how people reach them is important.</p>
<p>Our dataset is from Hugging Face and includes 900+ posts and labeled comments. We cleaned it and focused on responses that had clear sentiment labels. Our core question: can we predict who’s being criticized in a comment? Is it the original poster (OP), or someone else?</p>
<p>To test this, we compare two tools: Gemini (a large language model via API) and BERT (a popular open-source NLP model). This sets the stage for analyzing how each interprets tone and direction of criticism.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="methods-overview" class="slide level2 scrollable smaller">
<h2>Methods Overview</h2>
<ul>
<li><strong>Goal:</strong> Determine whether AITA comment sentiment is directed at the Original Poster (OP) or someone else.</li>
<li><strong>Step 1: Data Mapping</strong>
<ul>
<li>Used 5 original sentiment labels: <em>positive, negative, neutral, neutral (positive), neutral (negative)</em>.</li>
<li>Mapped to two categories:
<ul>
<li><strong>OP</strong> = Positive, Neutral (Positive), Neutral</li>
<li><strong>Other</strong> = Negative, Neutral (Negative)</li>
</ul></li>
</ul></li>
<li><strong>Step 2: Gemini Predictions</strong>
<ul>
<li>Prompted Gemini to classify each response: <em>“Is this criticizing the OP or someone else?”</em></li>
<li>Saved Gemini’s binary prediction: “OP” or “Other”</li>
</ul></li>
<li><strong>Step 3: BERT Model</strong>
<ul>
<li>Used <code>bert-base-uncased</code> in a text classification pipeline</li>
<li>Ran responses through BERT with truncation at 512 tokens</li>
<li>Saved predicted labels: “OP” or “Other”</li>
</ul></li>
<li><strong>Step 4: Evaluation</strong>
<ul>
<li>Compared both models to mapped sentiment labels using:
<ul>
<li>Confusion matrices</li>
<li>Precision, recall, F1-score</li>
<li>Chi-square test to compare prediction distributions</li>
</ul></li>
</ul></li>
</ul>
<aside class="notes">
<p>Here’s how we structured our approach.</p>
<p>First, we mapped all sentiment labels into binary classes. Positive, neutral-positive, and neutral were assumed to refer to the OP — since those sentiments tend to be supportive or neutral toward the main poster. Negative and neutral-negative were mapped to “Other,” assuming criticism was directed elsewhere.</p>
<p>Then we ran two models:</p>
<ul>
<li>Gemini was prompted using clear instructions to classify whether a comment criticizes the OP or not.</li>
<li>BERT was used as a pretrained model for binary classification. It doesn’t understand Reddit rules out of the box, so it’s more of a baseline.</li>
</ul>
<p>Finally, we evaluated model predictions against our mapped labels using confusion matrices and classification metrics. To check for statistical significance between model behaviors, we used a chi-square test.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-collection-and-annotation" class="slide level2 scrollable smaller">
<h2>Data Collection and Annotation</h2>
<ul>
<li><strong>Source:</strong>
<ul>
<li>Used the <a href="https://huggingface.co/datasets/Oguzz07/AmItheAsshole">r/AmITheAsshole dataset</a> from Hugging Face</li>
<li>Created by user Oguzz07</li>
<li>Includes: Post text, comment responses, and final subreddit verdicts (YTA, NTA, ESH, NAH)</li>
</ul></li>
<li><strong>Volume:</strong>
<ul>
<li>Over 1 million comments total</li>
<li>Focused on a subset of responses that had been sentiment-labeled</li>
</ul></li>
<li><strong>Annotation Strategy:</strong>
<ul>
<li>Dataset included human-assigned sentiment labels:
<ul>
<li><em>Positive, Negative, Neutral (positive), Neutral (negative), Neutral</em></li>
</ul></li>
<li>We mapped these into binary classes for target inference:
<ul>
<li><strong>OP</strong> = Positive, Neutral (positive), Neutral</li>
<li><strong>Other</strong> = Negative, Neutral (negative)</li>
</ul></li>
<li>Assumption: Sentiment directed at someone in the post reflects the target of criticism</li>
</ul></li>
<li><strong>Goal of Annotation:</strong>
<ul>
<li>Create a “ground truth” for training/evaluating language models</li>
<li>Labels do not directly say “OP” or “Other,” so this mapping is our interpretive layer</li>
</ul></li>
</ul>
<aside class="notes">
<p>Let’s talk about our data.</p>
<p>We used the r/AmITheAsshole dataset from Hugging Face, created by Oguzz07. It includes the post content, user comments, and final subreddit verdicts. Our focus was on the comments — specifically those that already had sentiment labels.</p>
<p>These labels were manually assigned and include not just “positive” or “negative,” but nuanced categories like “neutral (positive)” or “neutral (negative).” That granularity is great for analyzing tone.</p>
<p>But since there was no explicit label for “who” the comment targeted, we introduced an interpretive layer. We assumed that if a comment is positive or neutral, it likely supports the OP; if it’s negative or neutral-negative, it’s likely criticizing someone else.</p>
<p>This mapping let us create a supervised task where we could evaluate how well language models inferred that directionality of sentiment — toward OP or another party.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="analysis-methods" class="slide level2 scrollable smaller">
<h2>Analysis Methods</h2>
<ul>
<li><strong>Binary Classification Task:</strong>
<ul>
<li>Determine whether a Reddit response targets:
<ul>
<li><strong>OP</strong> (Original Poster)</li>
<li><strong>Other</strong> (another person mentioned)</li>
</ul></li>
</ul></li>
<li><strong>Model 1: Gemini (Google API)</strong>
<ul>
<li>Prompted with:<br>
&gt; “Analyze the following Reddit post and determine the sentiment of the response. If the response criticizes the Original Poster (OP), say ‘Other’. If the response criticizes someone else (not OP), say ‘OP’. Only respond with ‘OP’ or ‘Other’. Here is the Reddit post:”{response}“”</li>
<li>Collected responses via API call</li>
<li>Stored predictions as “OP” or “Other”</li>
</ul></li>
<li><strong>Model 2: BERT (bert-base-uncased)</strong>
<ul>
<li>Used Hugging Face’s text classification pipeline</li>
<li>Inputs truncated at 512 tokens</li>
<li>Model outputs label: “LABEL_0” or “LABEL_1” → mapped to “OP” or “Other”</li>
</ul></li>
<li><strong>Evaluation:</strong>
<ul>
<li>Compared both models to ground truth (mapped sentiment labels)</li>
<li>Used:
<ul>
<li><strong>Confusion Matrix</strong></li>
<li><strong>Precision, Recall, F1-Score</strong></li>
<li><strong>Chi-Square Test</strong> to assess if the two models differ significantly in behavior</li>
</ul></li>
</ul></li>
<li><strong>Tools:</strong>
<ul>
<li>Python (Pandas, Transformers, SciPy)</li>
<li>Google Colab for experimentation</li>
</ul></li>
</ul>
<aside class="notes">
<p>Now let’s get into our modeling setup.</p>
<p>We framed the task as binary classification: each Reddit comment either targets the OP or someone else. It’s simple but lets us explore how models process moral and interpersonal cues.</p>
<p>We used two tools: - Gemini, accessed via Google’s API, where we gave it a strict prompt and recorded whether it said “OP” or “Other.” - BERT, a widely used pretrained model, which we ran using the Hugging Face pipeline. We truncated inputs at 512 tokens to meet the model’s length limit.</p>
<p>Both models returned predictions, which we compared to our mapped labels. We calculated standard performance metrics: accuracy, precision, recall, and F1-score.</p>
<p>Then, we used a chi-square test to ask: do Gemini and BERT differ meaningfully in how they distribute their predictions? That helps us assess if model choice changes what moral reading we get from a comment.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="chi-square-test" class="slide level2 scrollable">
<h2>Chi-Square Test</h2>
<ul>
<li><p><strong>Why a chi-square test?</strong></p>
<ul>
<li>To check if Gemini and BERT make significantly different types of predictions</li>
<li>Compares how each model distributes errors (e.g., false positives, false negatives)</li>
</ul></li>
<li><p><strong>Contingency Table Input:</strong></p>
<table class="caption-top">
<colgroup>
<col style="width: 10%">
<col style="width: 18%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>True OP → OP</th>
<th>True OP → Other</th>
<th>True Other → OP</th>
<th>True Other → Other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gemini</td>
<td>714</td>
<td>97</td>
<td>47</td>
<td>24</td>
</tr>
<tr class="even">
<td>BERT</td>
<td>666</td>
<td>201</td>
<td>60</td>
<td>19</td>
</tr>
</tbody>
</table></li>
<li><p><strong>Results:</strong></p>
<ul>
<li>Chi² = 37.93<br>
</li>
<li>p-value = 2.92 × 10⁻⁸<br>
</li>
<li>DoF = 3</li>
</ul></li>
<li><p><strong>Interpretation:</strong></p>
<ul>
<li>Strong evidence that BERT and Gemini behave differently</li>
<li>Supports our argument that model choice matters in moral sentiment analysis</li>
</ul></li>
</ul>
<aside class="notes">
<p>This slide shows the statistical backbone of our model comparison.</p>
<p>The chi-square test checks whether Gemini and BERT make different types of mistakes. For example, are they both bad at identifying criticism of “Other” people? Or does one model tend to overclassify everything as OP?</p>
<p>We built a 2x2x2 contingency table with prediction outcomes from both models: - True OP → predicted OP - True OP → predicted Other - True Other → predicted OP - True Other → predicted Other</p>
<p>The results show a chi-square value of 37.93 and a p-value well below 0.000001. This means the differences between models are <strong>highly statistically significant</strong> — they don’t behave the same, and those differences aren’t random.</p>
<p>This test gives us solid evidence that Gemini and BERT interpret moral judgment in different ways.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results" class="slide level2 scrollable smaller">
<h2>Results</h2>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">Gemini Performance</a></li><li><a href="#tabset-2-2">BERT Performance</a></li><li><a href="#tabset-2-3">Comparison: Chi-Square Test</a></li><li><a href="#tabset-2-4">Confusion Matrix Heatmaps</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<ul>
<li><strong>Confusion Matrix:</strong>
<ul>
<li>True OP → OP: 714<br>
</li>
<li>True OP → Other: 97<br>
</li>
<li>True Other → OP: 47<br>
</li>
<li>True Other → Other: 24</li>
</ul></li>
<li><strong>Metrics:</strong>
<ul>
<li>Accuracy: <strong>84%</strong></li>
<li>OP F1-score: <strong>0.91</strong></li>
<li>Other F1-score: <strong>0.25</strong></li>
<li>Model tends to <strong>favor OP classification</strong>, underperforms on “Other”</li>
</ul></li>
</ul>
</div>
<div id="tabset-2-2">
<ul>
<li><strong>Confusion Matrix:</strong>
<ul>
<li>True OP → OP: 666<br>
</li>
<li>True OP → Other: 201<br>
</li>
<li>True Other → OP: 60<br>
</li>
<li>True Other → Other: 19</li>
</ul></li>
<li><strong>Metrics:</strong>
<ul>
<li>Accuracy: <strong>72%</strong></li>
<li>OP F1-score: <strong>0.84</strong></li>
<li>Other F1-score: <strong>0.13</strong></li>
<li>Weaker than Gemini overall, especially on minority class (“Other”)</li>
</ul></li>
</ul>
</div>
<div id="tabset-2-3">
<ul>
<li><strong>Statistical Test:</strong> χ² = 37.93, p &lt; 0.00000003</li>
<li><strong>Interpretation:</strong> Gemini and BERT <strong>distribute predictions significantly differently</strong></li>
<li><strong>Implication:</strong> Model choice affects who we think is being criticized in AITA — not all LLMs “read” judgment the same way</li>
</ul>
</div>
<div id="tabset-2-4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="heatmap.png"></p>
<figcaption>Confusion matrices for Gemini and BERT</figcaption>
</figure>
</div>
<ul>
<li><strong>Gemini (left):</strong> Stronger performance, especially for OP detection<br>
</li>
<li><strong>BERT (right):</strong> Weaker precision and recall on “Other” predictions<br>
</li>
<li>This visual shows how both models skew toward OP classification</li>
</ul>
</div>
</div>
</div>
<aside class="notes">
<p>Let’s break down what we found.</p>
<p><strong>Gemini</strong> performed better overall. It correctly predicted OP criticism more often and had a higher F1-score for both classes. Its accuracy was 84%, and it handled “Other” targets better than BERT did — though even Gemini struggled with minority class predictions.</p>
<p><strong>BERT</strong> lagged behind with a 72% accuracy. It was especially weak at catching “Other” criticism — that is, when someone in the post other than the OP was being judged.</p>
<p>This suggests BERT has trouble with context and social nuance. It’s likely treating all comments as if they’re about the main poster.</p>
<p>The heatmaps drive this home visually. Gemini’s predictions are more balanced; BERT heavily favors OP classification and misses nuance.</p>
<p>Together, these results show that even among advanced language models, some are better equipped to understand how people judge each other in online discourse.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="conclusion-and-limitations" class="slide level2 scrollable smaller">
<h2>Conclusion and Limitations</h2>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">Conclusion</a></li><li><a href="#tabset-3-2">Limitations</a></li><li><a href="#tabset-3-3">Future Directions</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<ul>
<li><strong>Key Insight:</strong>
<ul>
<li>Sentiment models like BERT and Gemini can approximate moral judgments in r/AmITheAsshole (AITA) discussions.</li>
</ul></li>
<li><strong>Model Comparison:</strong>
<ul>
<li><strong>Gemini</strong> outperformed BERT in identifying when criticism targets the OP.</li>
<li><strong>BERT</strong> struggled more with detecting criticism directed at others.</li>
</ul></li>
<li><strong>Statistical Significance:</strong>
<ul>
<li>A chi-square test revealed significant differences in prediction distributions between the two models (χ² = 37.93, p &lt; 0.00000003).</li>
</ul></li>
<li><strong>Implication:</strong>
<ul>
<li>The choice of language model significantly influences the interpretation of moral judgments in online discourse.</li>
</ul></li>
</ul>
</div>
<div id="tabset-3-2">
<ul>
<li><strong>Label Mapping:</strong>
<ul>
<li>The binary classification of “OP” vs.&nbsp;“Other” was derived from sentiment labels, which may not perfectly capture the target of criticism.</li>
</ul></li>
<li><strong>Model Training:</strong>
<ul>
<li>BERT was used without fine-tuning on AITA-specific data, potentially limiting its effectiveness.</li>
</ul></li>
<li><strong>Data Constraints:</strong>
<ul>
<li>Some responses exceeded the 512-token limit of BERT, leading to truncation and possible loss of context.</li>
</ul></li>
<li><strong>Annotation Ambiguity:</strong>
<ul>
<li>The interpretation of sentiment labels as indicators of criticism direction introduces subjectivity.</li>
</ul></li>
</ul>
</div>
<div id="tabset-3-3">
<ul>
<li><strong>Model Enhancement:</strong>
<ul>
<li>Fine-tune BERT on AITA-specific data to improve its understanding of nuanced moral judgments.</li>
</ul></li>
<li><strong>Expanded Annotation:</strong>
<ul>
<li>Incorporate more detailed annotations to better capture the directionality of criticism.</li>
</ul></li>
<li><strong>Broader Analysis:</strong>
<ul>
<li>Explore additional linguistic features and context to enhance model predictions.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<aside class="notes">
<p>To conclude: both models can <em>approximate</em> moral judgment in AITA posts, but they do it differently.</p>
<p>Gemini outperformed BERT, especially in identifying when the OP <em>wasn’t</em> the target. That matters — because understanding misfires or conflict direction is central to interpreting social media judgment.</p>
<p>However, we should be cautious: - Our labels were inferred from sentiment, not explicitly labeled as “OP” or “Other.” - BERT wasn’t fine-tuned for AITA — we used it off the shelf, which limits accuracy. - Some responses were too long and had to be truncated, which may have dropped important context.</p>
<p>Moving forward, we’d want to: - Fine-tune models on AITA-style data - Collect more granular labels - Incorporate relational or discourse-level features to improve context sensitivity</p>
<p>The takeaway? Model choice matters — and understanding how models “read” judgment is vital if we want to automate or analyze online discourse responsibly.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="questions" class="slide level2">
<h2>Questions?</h2>
</section>
<section id="thanks" class="slide level2">
<h2>Thanks !!</h2>
</section>
<section class="slide level2">

<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="COMP394_FP_presentation_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>